{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils_functions\n",
    "reload(utils_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Understanding and treating the data\n",
    "\n",
    "## Part 1.1 Data conversion\n",
    "\n",
    "The first step in our analysis is to ensure all data is represented consistently across the project. This involves converting the original **.txt** files containing ratings and reviews into **.csv** format. Each file was examined carefully, the strings were stored into dictionaries representing key data fiels. More details on the conversion process and methodology can be found in ????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 Data exploration\n",
    "\n",
    "With the data now in a consistent format, we begin exploring deeper the datasets to understand their links and features. We learn especially that some breweries, beers, users matches between the websites. Moreover, their might be duplicates within the datasets, with some users having multiple account. DO I MISS SOMETHING???. Further explanations can be found in ????? data_understanding... EXPLAIN THE FEATURES ?\n",
    "\n",
    "Some rows contain NaN values in the datasets. Since certain parts of the analysis do not require every feature, we handle missing data filtering it based on the requirements of each analysis section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3 Dataset merging\n",
    "To enhance the robustness of the analysis, we merge data from both RateBeer and BeerAdvocate. This approach increases the number of ratings per beer enabling a higher reliability and enhancing the controversiality analysis.\n",
    "\n",
    "We must first perform a little analysis to ensure compatibility between the two dataset. For example, we noticed that websites had different scale for the ratings. This is thus necessary to convert them into a similar one.\n",
    "\n",
    "When merging, we must be careful and take into account the different matched data between the two datasets, such as users, breweries etc...\n",
    "\n",
    "EXPLAIN DEEPER HOW THIS IS DONE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.getcwd()).parent\n",
    "\n",
    "#Change for each one of where your data is. For me in Dataset I have all the three folders\n",
    "dataset_path = os.path.join(root,'Dataset')\n",
    "\n",
    "FULL = \"full\"\n",
    "FULL_PATH = os.path.join(dataset_path,FULL)\n",
    "\n",
    "breweries_df = pd.read_csv(os.path.join(FULL_PATH, 'breweries.csv'))\n",
    "beers_df = pd.read_csv(os.path.join(FULL_PATH, 'beers.csv'))\n",
    "users_df = pd.read_csv(os.path.join(FULL_PATH, 'users.csv'))\n",
    "ratings_df = pd.read_csv(os.path.join(FULL_PATH,'ratings.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Exploring the definition of controversiality\n",
    "\n",
    "This part aims to determine and label which beers are controversial and which are universal. To do this, we explore different aspects defining the controversiality of a beer. \n",
    "\n",
    "What does controversial mean : \"giving rise or likely to give rise to controversy or public disagreement\". As described, this depends on the opinions of the people. As a result, this analysis only depends on the fields the users can fulfill, namely, the different ratings : appearance, aroma, palate, taste, overall, and the textual reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1 Ratings and reviews filtering\n",
    "\n",
    "As mentioned earlier, controversiality depends on disagreement in opinions. Beers with few ratings are more likely to show high variability (e.g. two opposing opinions). To ensure reliable insights and meaningful analysis, we exclude beers with fewer number of ratings or reviews than a specified threshold. Later, we might apply a weighting factor based on rating count to further refine the controversiality analysis, according more importance to more rated beers.\n",
    "\n",
    "The threshold deciding wheter to keep a beer in the analysis is chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Part 2.2, we want to have a DataFrame with the relevant features : id_beer, appearance, aroma, taste, palate, overall, ratings. We only keep the beer having enough ratings for a controversial analysis\n",
    "beer_ratings = filter_ratings(ratings_df, threshold=10, attributes=['appearance', 'aroma', 'palate', 'taste', 'overall', 'rating'])\n",
    "\n",
    "# For Part 2.3, we want to have a DataFrame with the relevant features : id_beer, text. The beer having enough reviews for a controversial analysis\n",
    "beer_reviews = filter_ratings(ratings_df, threshold=10, attributes=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_ratings.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2 Features controversiality analysis\n",
    "\n",
    "Controversiality can be analyzed in different manners. For now, the three following definitions are studied :\n",
    "\n",
    "- We compute the variance of each attributes for each beer, then study which attribute seems to be the more controversial by looking at the distribution of the variances.\n",
    "- We compute the variance across the **overall** rating, provided by the user. We then classify beers as controversial if above a certain threshold. Then, we observe which of the four main attributes influences the most the overall score controversiality.\n",
    "- We count for each beer which attributes is the most and lest controversial.\n",
    "\n",
    "\n",
    "\n",
    "WE COULD APPLY A WEIGHT AS A FUNCTION OF THE NUMBER OF RATINGS ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2.1 Features analysis controversiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_variance = compute_variance_per_attribute(beer_ratings, ['appearance', 'aroma', 'palate', 'taste'])\n",
    "attributes_variance.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_variance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plot box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2.2 Features analysis from overall controversiality\n",
    "\n",
    "In this part, we want to try analyzing the attributes using the variance of the overall feature. We classify a beer as controversial/universal according to overall variance and then study the variance of the attributes within these class. This can be done by :\n",
    "1) Defining value threshold \n",
    "2) Selecting the highest and lowest pourcentage of the distribution of variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[controv_rating_basic_attributes_var, univ_rating_basic_attributes_var] = classify_value_threshold(ratings_df, ['appearance', 'aroma', 'palate', 'taste'], ['overall'], 0.5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_rating_basic_attributes_var.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[controv_rating_basic_attributes_var, univ_rating_basic_attributes_var] = classify_percentage_distribution(ratings_df, ['appearance', 'aroma', 'palate', 'taste'], ['overall'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controv_rating_basic_attributes_var.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify controversiality as a function of overall variance with threshold or %\n",
    "# describe it\n",
    "# box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2.3 Feature analysis from count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of max min variance attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2.4 Correlation between the variance of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of the attribute's variances with overall variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2.5 PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3 Sentimental analysis of the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4 Which beer is controversial then ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4.1 Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4.2 Statistical testing and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Some reasons of controversiality\n",
    "\n",
    "This part uses the label attributed to the beers. It tries to find patterns and reasons of controversial opinion as a function of \"constant\" variables such as abv and style of the beer, location of the brewery and the users, level of expertise of the users..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.1 Novice/Enthusiasts/Connoisseur analysis\n",
    "\n",
    "In this part, we classify the users related to how many ratings they did.\n",
    "\n",
    "- Novice are users with only a few ratings : 1-20.\n",
    "- Enthusiasts are users with moderate number of ratings : 21-100\n",
    "- Connoisseur are users with high nuber of ratings . 101+\n",
    "\n",
    "It is important to note that this choice has been arbitrarily made. It could be made differently or could be interactive for the reader of the story, enabling him to label users differently according to how many ratings he thinks is enough to be a connoisseur/enthusiasts/novice.\n",
    "\n",
    "Another essential thing to take into account is that these classes do not represent users as novice or connoisseur about **beers**, but about **rating** on these particular website.\n",
    "\n",
    "First step is to classify the users in the three mentioned categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = classify_user_rating_level(user_df, enthusiasts_level=21, connoisseur_level=101)\n",
    "plot_category_distrib(user_df, 'rating_user_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2 Style of the beer and abv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2 Patterns in location and ratings of local or foreign beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under construction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
